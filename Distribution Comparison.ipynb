{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f991f2e5",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c734661",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29e43b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import locale\n",
    "def getpreferredencoding(do_setlocale = True):\n",
    "    return \"UTF-8\"\n",
    "locale.getpreferredencoding = getpreferredencoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfb35d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers==4.22.2\n",
    "\n",
    "!pip install statsmodels\n",
    "\n",
    "!pip install datasets\n",
    "\n",
    "!pip install -U tensorflow==2.10 \n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ec6474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from tqdm.autonotebook import tqdm\n",
    "import spacy\n",
    "import re\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import scipy\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, mean_absolute_percentage_error, r2_score, jaccard_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# specific machine learning functionality\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras import backend as K\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "from datasets import load_from_disk\n",
    "\n",
    "# Transformers\n",
    "import transformers\n",
    "from transformers import (\n",
    "    BertTokenizer, \n",
    "    TFBertForSequenceClassification, \n",
    "    TFBertForMaskedLM, \n",
    "    TFBertModel,\n",
    "    #create_optimizer,\n",
    "    #DataCollatorForLanguageModeling,\n",
    "    #PreTrainedTokenizerFast\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b465e760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable/Disable Eager Execution\n",
    "# Reference: https://www.tensorflow.org/guide/eager\n",
    "# TensorFlow's eager execution is an imperative programming environment that evaluates operations immediately, \n",
    "# without building graphs\n",
    "\n",
    "#tf.compat.v1.disable_eager_execution()\n",
    "#tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "print(\"tensorflow version\", tf.__version__)\n",
    "print(\"keras version\", tf.keras.__version__)\n",
    "print(\"Eager Execution Enabled:\", tf.executing_eagerly())\n",
    "\n",
    "# Get the number of replicas \n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print(\"Number of replicas:\", strategy.num_replicas_in_sync)\n",
    "\n",
    "devices = tf.config.experimental.get_visible_devices()\n",
    "print(\"Devices:\", devices)\n",
    "print(tf.config.experimental.list_logical_devices('GPU'))\n",
    "\n",
    "print(\"GPU Available: \", tf.config.list_physical_devices('GPU'))\n",
    "print(\"All Physical Devices\", tf.config.list_physical_devices())\n",
    "\n",
    "# Better performance with the tf.data API\n",
    "# Reference: https://www.tensorflow.org/guide/data_performance\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38980666",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dir = \"/content/drive/MyDrive/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2627fb22",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9298bd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "qadataset = datasets.load_dataset(\"squad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9cf340",
   "metadata": {},
   "source": [
    "# Labeling the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc6fbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "qadataset_train = qadataset['train']\n",
    "qadataset_test = qadataset['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727d942d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_negative(example):\n",
    "    context = example['context']\n",
    "    answer_start = example['answers']['answer_start'][0]\n",
    "    sentence_number = context[:answer_start].count(\".\")\n",
    "    sentences = context.split(\".\")\n",
    "    example['context'] = '.'.join(sentences[:sentence_number] + sentences[sentence_number+1:])\n",
    "    example['label'] = False\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8fc637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_positive(example):\n",
    "    example['label'] = True\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a541a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "qadataset_train_label_split = qadataset_train.train_test_split(test_size=0.5, shuffle=True, seed=109)\n",
    "\n",
    "qadataset_train_positive = qadataset_train_label_split['train']\n",
    "qadataset_train_negative = qadataset_train_label_split['test']\n",
    "\n",
    "qadataset_train_negative = qadataset_train_negative.map(make_negative)\n",
    "qadataset_train_positive = qadataset_train_positive.map(make_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97be59d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "qadataset_test_label_split = qadataset_test.train_test_split(test_size=0.5, shuffle=True, seed=109)\n",
    "\n",
    "qadataset_test_positive = qadataset_test_label_split['train']\n",
    "qadataset_test_negative = qadataset_test_label_split['test']\n",
    "\n",
    "qadataset_test_positive = qadataset_test_positive.map(make_positive)\n",
    "qadataset_test_negative = qadataset_test_negative.map(make_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e09c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "qadataset_train = datasets.concatenate_datasets([qadataset_train_positive, qadataset_train_negative])\n",
    "qadataset_test = datasets.concatenate_datasets([qadataset_test_positive, qadataset_test_negative])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcc3e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_q_a(example):\n",
    "    example['text'] = '[CLS] ' + example['question'] + ' [SEP] ' + example['context']\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401dcc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "qadataset_train = qadataset_train.map(combine_q_a)\n",
    "qadataset_test = qadataset_test.map(combine_q_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14025d4a",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfb5d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tokenization parameters\n",
    "classifier_name = 'bert-base-uncased'\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(classifier_name, do_lower_case=True)\n",
    "batch_size = 8 \n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c04f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tokenization function\n",
    "def tokenize_for_bert_classifier(df, should_shuffle=False):\n",
    "    # Tokenization\n",
    "    X_tokenized = bert_tokenizer.batch_encode_plus(\n",
    "            df[\"text\"],\n",
    "            return_tensors='tf',\n",
    "            add_special_tokens = True,\n",
    "            return_token_type_ids=True,\n",
    "            padding='max_length',\n",
    "            max_length=256,\n",
    "            return_attention_mask = True,\n",
    "            truncation='longest_first'\n",
    "    )\n",
    "    # Creating TF datasets\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(((X_tokenized[\"input_ids\"],\n",
    "                                                   X_tokenized[\"token_type_ids\"],\n",
    "                                                   X_tokenized[\"attention_mask\"]), \n",
    "                                                  df[\"label\"]))\n",
    "    if should_shuffle:\n",
    "        buffer_train = len(df[\"text\"])\n",
    "        dataset = dataset.shuffle(buffer_size=buffer_train)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15052733",
   "metadata": {},
   "outputs": [],
   "source": [
    "qadataset_train = qadataset_train.train_test_split(test_size=0.2, shuffle=True, seed=109)\n",
    "\n",
    "qadataset_train['validation'] = qadataset_train.pop('test')\n",
    "\n",
    "classification_training_data = tokenize_for_bert_classifier(qadataset_train['train'], should_shuffle=True)\n",
    "classification_validation_data = tokenize_for_bert_classifier(qadataset_train['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1b7f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_test_data = tokenize_for_bert_classifier(qadataset_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebcbb47",
   "metadata": {},
   "source": [
    "# Filter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b302c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_test_data = tokenize_for_bert_classifier(qadataset_test)\n",
    "Y_pred = classifier_model.predict(classification_test_data)\n",
    "Y_pred = Y_pred['logits'] > 0\n",
    "Y_pred_flat = [temp[0] for temp in Y_pred]\n",
    "qadataset_test = qadataset_test.add_column(\"predicted label\", Y_pred_flat)\n",
    "\n",
    "qadataset_test_TP = qadataset_test.filter(lambda example: example[\"label\"] == example[\"predicted label\"])\n",
    "\n",
    "qadataset_test_TP = qadataset_test_TP.filter(lambda example: example[\"label\"] == True)\n",
    "\n",
    "qadataset_test_TP = qadataset_test_TP.filter(lambda example: len(np.unique(example[\"answers\"][\"answer_start\"])) == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c2e77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "qadataset_test_TP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d945b9",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686338fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFBertModel.from_pretrained(\"/content/drive/MyDrive/Senior Thesis models/model_classifier_bert_6/temp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a585ce6",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c62d88f",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade880fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = qadataset_test_TP\n",
    "test_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a815aa06",
   "metadata": {},
   "source": [
    "### Masking Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beab9a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_masked_sample(example):\n",
    "    text = example[\"text\"]\n",
    "    all_words = text.split()\n",
    "\n",
    "    question_length = len(example['question'].split()) \n",
    "    full_length = len(all_words) \n",
    "    masking_size = int((full_length - question_length) * 0.15 + 1)\n",
    "\n",
    "    word_indices = np.random.choice(\n",
    "      range(question_length, full_length), \n",
    "      size=masking_size,\n",
    "      replace = False,\n",
    "    )\n",
    "    text_with_deletion = \" \".join([temp_word if j not in word_indices else \"\" for (j, temp_word) in enumerate(all_words)])\n",
    "    example[\"text_with_deletion\"] = text_with_deletion\n",
    "\n",
    "    text_with_masking = \" \".join([temp_word if j not in word_indices else \"[MASK]\" for (j, temp_word) in enumerate(all_words)])\n",
    "    example[\"text_with_masking\"] = text_with_masking\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80952441",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(109)\n",
    "test_sample = test_sample.map(get_masked_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f26b12e",
   "metadata": {},
   "source": [
    "### Replacement Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d5b68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_replacement_sample(example):\n",
    "    text = example[\"text_with_masking\"]\n",
    "    all_words = example[\"text\"].split()\n",
    "\n",
    "    question_length = len(example['question'].split()) \n",
    "    full_length = len(all_words) \n",
    "    masking_size = int((full_length - question_length) * 0.15 + 1)\n",
    "\n",
    "    # get gap filler logits\n",
    "    inputs = bert_tokenizer(text, return_tensors=\"tf\")\n",
    "    logits = gap_untuned_model(**inputs).logits\n",
    "\n",
    "    # retrieve indices of [MASK]\n",
    "    mask_token_index = tf.where((inputs.input_ids == bert_tokenizer.mask_token_id)[0])\n",
    "    selected_logits = tf.gather_nd(logits[0], indices=mask_token_index)\n",
    "\n",
    "    # get top predictions\n",
    "    top_k_words = 10\n",
    "    predicted_token_ids = [tf.math.argmax(temp, axis=-1) for temp in selected_logits]\n",
    "    options = [bert_tokenizer.decode([temp]) for temp in predicted_token_ids]\n",
    "\n",
    "    # get scores of those predictions\n",
    "    filled_sentence = text\n",
    "    for j in range(masking_size):\n",
    "        filled_sentence = filled_sentence.replace(\"[MASK]\", options[j], 1)\n",
    "    example[\"text_with_replacement\"] = filled_sentence\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a608fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(109)\n",
    "test_sample = test_sample.map(get_replacement_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d38aeec",
   "metadata": {},
   "source": [
    "### Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897bf4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.DataFrame()\n",
    "df_original[\"text\"] = test_sample[\"text\"]\n",
    "df_original[\"source\"] = \"original\"\n",
    "\n",
    "df_deletion = pd.DataFrame()\n",
    "df_deletion[\"text\"] = test_sample[\"text_with_deletion\"]\n",
    "df_deletion[\"source\"] = \"deletion\"\n",
    "\n",
    "df_replacement = pd.DataFrame()\n",
    "df_replacement[\"text\"] = test_sample[\"text_with_replacement\"]\n",
    "df_replacement[\"source\"] = \"replacement\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a88db61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tsne = pd.concat([df_replacement, df_deletion, df_original], \n",
    "                    ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e613e9f0",
   "metadata": {},
   "source": [
    "### BERT Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1c61c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tokenize all the data\n",
    "text_encoding = bert_tokenizer.batch_encode_plus(df_tsne['text'],\n",
    "                                                  return_tensors='tf',\n",
    "                                                  add_special_tokens = True,\n",
    "                                                  return_token_type_ids=True,\n",
    "                                                  padding='max_length',\n",
    "                                                  max_length=256,\n",
    "                                                  return_attention_mask = True,\n",
    "                                                  truncation='longest_first')\n",
    "text_encoding_dataset = tf.data.Dataset.from_tensor_slices((text_encoding[\"input_ids\"],\n",
    "                                                             text_encoding[\"token_type_ids\"],\n",
    "                                                             text_encoding[\"attention_mask\"]))\n",
    "text_encoding_dataset = text_encoding_dataset.batch(batch_size)\n",
    "text_encoding_dataset = text_encoding_dataset.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2727cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get pooled outputs, which are the outputs of the last layer of Bert\n",
    "embedding_to_concat = []\n",
    "for batch in tqdm(text_encoding_dataset):\n",
    "    batch_embedding = model(batch)\n",
    "    embedding_to_concat.append(batch_embedding['pooler_output'])\n",
    "text_hidden_layer = tf.concat(embedding_to_concat, axis = 0).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc49431d",
   "metadata": {},
   "source": [
    "## TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b8d4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get TSNE components\n",
    "text_tsne_representation = TSNE(n_components=2, random_state = 109).fit_transform(text_hidden_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b562ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tsne_x = [temp[0] for temp in text_tsne_representation]\n",
    "text_tsne_y = [temp[1] for temp in text_tsne_representation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ebba04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tsne[\"x_tsne\"] = text_tsne_x\n",
    "df_tsne[\"y_tsne\"] = text_tsne_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da08379",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot\n",
    "groups = df_tsne.groupby('source', sort = False)\n",
    "colors = [\"#332288\", (0.53, 0.8, 0.93, 0.5), \"orange\"]\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "for current_color, (name, group) in zip(colors, groups):\n",
    "  plt.scatter(group.x_tsne, group.y_tsne, label = name, color = current_color)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2cfeb1",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca21d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get TSNE components\n",
    "text_hidden_layer_standardized = StandardScaler().fit_transform(text_hidden_layer)\n",
    "text_pca_representation = PCA(n_components=2, random_state = 109).fit_transform(text_hidden_layer_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc41c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pca_x = [temp[0] for temp in text_pca_representation]\n",
    "text_pca_y = [temp[1] for temp in text_pca_representation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ba9a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tsne[\"x_pca\"] = text_pca_x\n",
    "df_tsne[\"y_pca\"] = text_pca_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2be13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot\n",
    "groups = df_tsne.groupby('source', sort = False)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "for current_color, (name, group) in zip(colors, groups):\n",
    "  plt.scatter(group.x_pca, group.y_pca, label = name, color = current_color)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dac965a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot\n",
    "groups = df_tsne.groupby('source', sort = False)\n",
    "\n",
    "\n",
    "for current_color, (name, group) in zip(colors, groups):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(group.x_pca, group.y_pca, label = name, color = current_color)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cf70cc",
   "metadata": {},
   "source": [
    "# FID Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5773875f",
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_data = text_hidden_layer[:2784]\n",
    "deletion_data = text_hidden_layer[2784:5568]\n",
    "original_data = text_hidden_layer[5568:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263a98cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fid(x, y):\n",
    "    mu_x = np.mean(x, axis = 0)\n",
    "    mu_y = np.mean(y, axis = 0)\n",
    "\n",
    "    cov_x = np.cov(x, rowvar=False)\n",
    "    cov_y = np.cov(y, rowvar=False)\n",
    "\n",
    "    mu_difference = np.sum((mu_x - mu_y) ** 2)\n",
    "    cov_sqrt = scipy.linalg.sqrtm(np.dot(cov_x, cov_y))\n",
    "    if np.iscomplexobj(cov_sqrt):\n",
    "        cov_sqrt = cov_sqrt.real\n",
    "    fid = mu_difference + np.trace(cov_x + cov_y - 2.0 * cov_sqrt)\n",
    "    return fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10a73f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_fid(original_data, deletion_data)\n",
    "\n",
    "calculate_fid(original_data, replacement_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba04d584",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
