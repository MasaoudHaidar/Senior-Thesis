{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "267c4b6e",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26efea43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e87d425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import locale\n",
    "def getpreferredencoding(do_setlocale = True):\n",
    "    return \"UTF-8\"\n",
    "locale.getpreferredencoding = getpreferredencoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12beee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers==4.22.2\n",
    "\n",
    "!pip install statsmodels\n",
    "\n",
    "!pip install datasets\n",
    "\n",
    "!pip install -U tensorflow==2.10 \n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f777bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from tqdm.autonotebook import tqdm\n",
    "import spacy\n",
    "import re\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import scipy\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, mean_absolute_percentage_error, r2_score, jaccard_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# specific machine learning functionality\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras import backend as K\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "from datasets import load_from_disk\n",
    "\n",
    "# Transformers\n",
    "import transformers\n",
    "from transformers import (\n",
    "    BertTokenizer, \n",
    "    TFBertForSequenceClassification, \n",
    "    TFBertForMaskedLM, \n",
    "    TFBertModel,\n",
    "    create_optimizer,\n",
    "    DataCollatorForLanguageModeling\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a74495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable/Disable Eager Execution\n",
    "# Reference: https://www.tensorflow.org/guide/eager\n",
    "# TensorFlow's eager execution is an imperative programming environment that evaluates operations immediately, \n",
    "# without building graphs\n",
    "\n",
    "#tf.compat.v1.disable_eager_execution()\n",
    "#tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "print(\"tensorflow version\", tf.__version__)\n",
    "print(\"keras version\", tf.keras.__version__)\n",
    "print(\"Eager Execution Enabled:\", tf.executing_eagerly())\n",
    "\n",
    "# Get the number of replicas \n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print(\"Number of replicas:\", strategy.num_replicas_in_sync)\n",
    "\n",
    "devices = tf.config.experimental.get_visible_devices()\n",
    "print(\"Devices:\", devices)\n",
    "print(tf.config.experimental.list_logical_devices('GPU'))\n",
    "\n",
    "print(\"GPU Available: \", tf.config.list_physical_devices('GPU'))\n",
    "print(\"All Physical Devices\", tf.config.list_physical_devices())\n",
    "\n",
    "# Better performance with the tf.data API\n",
    "# Reference: https://www.tensorflow.org/guide/data_performance\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e93e5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dir = \"/content/drive/MyDrive/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f543eec2",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286df491",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"data/IMDB Dataset.csv\")\n",
    "df = pd.read_csv(word_dir + \"Colab Notebooks/IMDB Dataset.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabbb31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gap_filler, df_classification = train_test_split(df, test_size=0.5, random_state=1, stratify=df[\"label\"])\n",
    "print(f\"Positive Rate in Gap filler data: {np.mean(df_gap_filler.label)}\")\n",
    "print(f\"Positive Rate in Classifier data: {np.mean(df_classification.label)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ccefb9",
   "metadata": {},
   "source": [
    "# Tune Gap Filler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4333938e",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2223aebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tokenization parameters\n",
    "classifier_name = 'bert-base-uncased'\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(classifier_name, do_lower_case=True)\n",
    "batch_size = 8 \n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389ebd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### BERT LM Setup\n",
    "learning_rate = 2e-5\n",
    "epochs = 2\n",
    "gap_filler_model_name = \"bert-base-uncased\"\n",
    "train_dataset = None\n",
    "\n",
    "def get_bert_LM():\n",
    "    return TFBertForMaskedLM.from_pretrained(gap_filler_model_name)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return bert_tokenizer(\n",
    "        examples[\"text\"], \n",
    "        return_special_tokens_mask=True,\n",
    "        padding='max_length',\n",
    "        max_length=256,\n",
    "        truncation='longest_first',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19844cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe move this and all following to only execute at train\n",
    "raw_dataset = Dataset.from_pandas(df_gap_filler)\n",
    "tokenized_datasets = raw_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    batch_size=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d4b59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices, val_indices = train_test_split(\n",
    "    list(range(len(tokenized_datasets))), test_size=0.2\n",
    ")\n",
    "\n",
    "train_dataset = tokenized_datasets.select(train_indices)\n",
    "eval_dataset = tokenized_datasets.select(val_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6456eb0",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2343c4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_bert_LM():\n",
    "    # Free up memory\n",
    "    K.clear_session()\n",
    "\n",
    "    # Build the model\n",
    "    model = get_bert_LM()\n",
    "\n",
    "    # Print the model architecture\n",
    "    print(model.summary())\n",
    "\n",
    "    # get number of steps\n",
    "    if train_dataset:\n",
    "        num_train_steps = len(train_dataset) * epochs\n",
    "\n",
    "        # Compile\n",
    "        optimizer, _lr_schedule = create_optimizer(\n",
    "          init_lr=learning_rate,\n",
    "          num_train_steps=num_train_steps,\n",
    "          num_warmup_steps=0\n",
    "        )\n",
    "        model.compile(optimizer=optimizer, run_eagerly=True)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778553e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_tuned_model = get_compiled_bert_LM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575c1341",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=bert_tokenizer, return_tensors=\"tf\"\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cc6048",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = tf.data.Options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed8c68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_dataset = gap_tuned_model.prepare_tf_dataset(\n",
    "    train_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    ").with_options(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeda6395",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_eval_dataset = gap_tuned_model.prepare_tf_dataset(\n",
    "  eval_dataset,\n",
    "  batch_size=8,\n",
    "  shuffle=False,\n",
    "  collate_fn=data_collator,\n",
    "  drop_remainder=True,\n",
    ").with_options(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581fbe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model = False\n",
    "if train_model:\n",
    "    start_time = time.time()\n",
    "    history = gap_tuned_model.fit(\n",
    "      tf_train_dataset,\n",
    "      validation_data=tf_eval_dataset,\n",
    "      epochs=epochs,\n",
    "    )\n",
    "    execution_time = (time.time() - start_time)/60.0\n",
    "    print(\"Training execution time (mins)\",execution_time)\n",
    "    gap_tuned_model.save_pretrained(word_dir + 'Senior Thesis models/model_LM_bert_1/temp')\n",
    "else:\n",
    "    gap_tuned_model = TFBertForMaskedLM.from_pretrained(word_dir + 'Senior Thesis models/model_LM_bert_1/temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54588f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
